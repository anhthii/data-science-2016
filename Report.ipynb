{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Đồ án cuối kỳ môn khoa học dữ liệu CQ2016/2\n",
    "\n",
    "## Đề tài: Phân loại danh mục của sản phẩm dựa trên tên sản phẩm\n",
    "\n",
    "## <font color='blue'> Chi tiết quy trình thu thập dữ liệu, phân tích, huấn luyện dữ liệu để đưa ra model máy học dự đoán danh mục sản phẩm được chia làm những bước chính sau đây </font>\n",
    "\n",
    "## Mục lục trình bày các bước:\n",
    "* [B1: Thu thập dữ liệu  ](#first-bullet)\n",
    "* [B2: Tiền xử lý dữ liệu](#second-bullet)\n",
    "* [B3: Chuyển data dạng text sang vector](#second-bullet)\n",
    "* [B4: Áp dụng các mô hình máy học khác nhau để huấn luyện dữ liệu, chọn ra mô hình tối ưu nhất](#second-bullet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re  # For preprocessing\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B1: Thu thập dữ liệu  <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "\n",
    "Nhóm thực hiện thu thập dữ liệu trên trang [tiki.vn](https://tiki.vn/). Trước khi thu thập nhóm đã kiểm tra file `robot.txt` và thấy dữ liệu thu thập được hoàn toàn được trang tiki cho phép và hợp lệ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session = HTMLSession()\n",
    "r = session.get('https://tiki.vn/')\n",
    "r.encoding = 'utf-8'\n",
    "\n",
    "data = []\n",
    "link_category_dict = dict()\n",
    "\n",
    "def parse_link(href, currentPage = 1):\n",
    "    page = href+\"&page=\"+str(currentPage)\n",
    "    _session = HTMLSession()\n",
    "    _r = _session.get(page)\n",
    "    items = _r.html.find('.content .title')\n",
    "\n",
    "    if len(items) == 0:\n",
    "        return\n",
    "    for item in items:\n",
    "        category = link_category_dict[href]\n",
    "        data.append([item.text.strip().rstrip(\".\"), category])\n",
    "    nextPage = currentPage+1\n",
    "    try:\n",
    "        print(\"page \", page)\n",
    "        parse_link(href, nextPage)\n",
    "    except Exception as e:\n",
    "        print(\"some errors occured\", str(e))\n",
    "\n",
    "def get_categories():\n",
    "    categories = []\n",
    "    item_list = r.html.find('li.MenuItem-tii3xq-0 ')\n",
    "    for item in item_list:\n",
    "        href = item.find('a', first=True).attrs[\"href\"]\n",
    "        category = item.text\n",
    "        categories.append((href, category))\n",
    "        link_category_dict[href] = category\n",
    "    return categories\n",
    "\n",
    "def crawl_data():\n",
    "    category_tuples = get_categories()\n",
    "    for category_tuple in category_tuples:\n",
    "        (href, category_name) = category_tuple\n",
    "        # Không cần sleep vì tiki.vn đã có cơ chế rate limit request\n",
    "        parse_link(href)\n",
    "\n",
    "def save_data():\n",
    "    np.random.shuffle(data)\n",
    "    if len(data) != 0:\n",
    "        with open('product.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"product_title\", \"category\"])\n",
    "            for item in data:\n",
    "                writer.writerow(item)\n",
    "\n",
    "category_tuples = get_categories()\n",
    "categorydf = pd.DataFrame(list(category_tuples), columns=['đường dẫn', 'tên danh mục'])\n",
    "display(categorydf)\n",
    "def run():\n",
    "    print(\"start crawling\")\n",
    "    crawl_data()\n",
    "    save_data()\n",
    "\n",
    "# uncomment run() to start crawling data\n",
    "# run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi thực hiện lấy danh sách các link danh mục sản phẩm như trên ta tiến hành thu thập dữ liệu đối với từng link. Crawler sẽ crawl hết tất cả các trang đối với từng danh mục bằng cách sử dungj param `page=` truyền vào request url sẽ có dạng như sau\n",
    "\n",
    "https://tiki.vn/dien-thoai-may-tinh-bang/c1789?src=c.1789.hamburger_menu_fly_out_banner&_lc=Vk4wMzkwMTIwMDQ%3D?page=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi crawl dữ liệu thành công ta đọc dữ liệu từ file `product.csv` và tạo data frame bằng pandas. Ta được mẫu dữ liệu như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('product.csv')\n",
    "print(\"count = \", df.count())\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiến hành thống kê số lượng sản phẩm cho mỗi danh mục sau khi thu thập được"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "colors = ['cyan','green','orange','blue','red','grey','purple','black','grey',\n",
    "    'turquoise','violet','navy','darkblue']\n",
    "df.groupby('category').product_title.count().sort_values().plot.barh(\n",
    "    ylim=0, color=colors, title='Số sản phẩm ứng với mỗi danh mục')\n",
    "plt.xlabel('Số sản phẩm', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B2: Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi dữ liệu được thu thập, chúng ta cần xử lý dữ liệu để phục vụ việc training dữ liệu được tốt hơn\n",
    "Chẳng hạn 1 dòng dữ liệu có `title` như sau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[142177][\"product_title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ở ví dụ trên, ta thấy có những thông tin thừa thải không cần được đưa vào mô hình để huấn luyện như là các chữ `Combo`, `4`, `(150g)`. Vì vậy công việc tiền xử lý sẽ loại bỏ những thông tin này\n",
    "Với ví dụ trên, ta mong muốn qua bước tiền xử lý. Thông tin còn lại sẽ là:\n",
    "\n",
    "Combo 4 hộp Gà Hầm Vissan (150g) => <font color='red'>hộp Gà Hầm Vissan</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy danh sách các stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(line.strip() for line in open('stopword.txt'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tạo class `TextPreprocessor` implement interface `transformer` của Sklearn. TextPreprocessor sẽ làm nhiệm vụ lowercase, xoá các stopword, số, các kí tự đặc biệt, dấu chấm câu khỏi product_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stop_words = []):\n",
    "        self.stop_words = stop_words\n",
    "    def fit(self, X_df, y=None):\n",
    "        categories = X_df['category'].unique()\n",
    "        # Thêm cột category_id, map category thành số \n",
    "        self.category_to_id = {}\n",
    "        assign_id = 0\n",
    "        for category in categories:\n",
    "            self.category_to_id[category] = assign_id\n",
    "            assign_id += 1  # Get a new id for new author\n",
    "        # Dict lưu key: id, value: tên category    \n",
    "        self.id_to_category = {v: k for k, v in self.category_to_id.items()}\n",
    "        \n",
    "    def id_to_categoryname(self, category_id):\n",
    "        return self.id_to_category[category_id]\n",
    "    \n",
    "    def get_category_id(self, category):\n",
    "        return self.category_to_id[category]\n",
    "    \n",
    "    def cleanText(self, text): \n",
    "        # Convert text to lower\n",
    "        text = text.lower()\n",
    "        # Removing non alphabetic words\n",
    "        # word contains number | hyphen | paranthesis\n",
    "        text = re.sub(r'\\S*\\d\\S*|-|\\(.*\\)', r'', text)\n",
    "\n",
    "        # Removing all the stopwords\n",
    "        filtered_words = [word for word in text.split() if word not in stop_words]\n",
    "        text = \" \".join(filtered_words)\n",
    "\n",
    "        # strip multiple spaces\n",
    "        text = re.sub(' +', ' ', text)\n",
    "\n",
    "        # strip punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def transform(self, X_df, y=None):\n",
    "        new_X_df = X_df.copy()\n",
    "        new_X_df['category_id'] = new_X_df['category'].map(self.get_category_id)\n",
    "        new_X_df.drop(['category'], axis=1)\n",
    "        new_X_df[\"product_title\"] = new_X_df[\"product_title\"].map(self.cleanText)        \n",
    "        return new_X_df\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu trước khi tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dữ liệu sau tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "textProcessor = TextPreprocessor(stop_words)\n",
    "textProcessor.fit(df)\n",
    "transformed_df = textProcessor.transform(df)\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.loc[142177][\"product_title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vậy là từ `Combo 4 hộp Gà Hầm Vissan (150g)`, dữ liệu đã được tiền xử lý và trở thành `hộp gà hầm vissan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bước 3: Chuyển data dạng text sang vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tách tập huấn huấn luyện, tập test từ data được tiền xử lý"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách tập (train + validation) và tập test theo tỉ lệ 70%:30%\n",
    "\n",
    "X_trainVal, X_test, y_trainVal, y_test = train_test_split(\n",
    "    transformed_df['product_title'], transformed_df['category_id'], test_size=0.33, random_state=42)\n",
    "\n",
    "# tách tập thành tập train và validation từ tập trainVal\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainVal, y_trainVal, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chuyển data text sang vector số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer= \"word\", stop_words=stop_words)\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dữ liệu text của tập validation sang vector từ model đã thu được trươc đó\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_counts = count_vect.transform(X_val)\n",
    "X_val_tfidf = tfidf_transformer.transform(X_val_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B4: Dùng các model máy học khác nhau để dự đoán"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tạo model dự đoán naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dùng model dự đoán tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomialNB_predict = mnb_clf.predict(X_val_tfidf)\n",
    "multinomialNB_score = accuracy_score(y_val, multinomialNB_predict) * 100\n",
    "print(\"Naive bayes Accuracy Score -> \", multinomialNB_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dùng model Linear support vector machine (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3,\n",
    "                    random_state=42, max_iter=5, tol=None).fit(X_train_tfidf, y_train)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "sdg_predict = sgd_clf.predict(X_val_tfidf)\n",
    "sgd_score = accuracy_score(y_val, sdg_predict) * 100\n",
    "print(\"SGD Accuracy Score -> \", sgd_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dùng model Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgt_clf = LogisticRegression(n_jobs=1, C=1e5, max_iter=100, solver='lbfgs', multi_class='auto').fit(X_train_tfidf, y_train)\n",
    "predictions_LGT = lgt_clf.predict(X_val_tfidf)\n",
    "lgt_score = accuracy_score(y_val, predictions_LGT) * 100\n",
    "print(\"LGT Accuracy Score -> \", lgt_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ('Naive Bayes', 'SGD', 'Logistic Regression')\n",
    "y_pos = np.arange(len(objects))\n",
    "scores = [multinomialNB_score,sgd_score, lgt_score]\n",
    "\n",
    "plt.bar(y_pos, scores, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Score for text classfication prediction models')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi chạy xong 3 mô hình máy học khác nhau thì ta thấy mô hình logistic regression có kết quả tốt nhất.\n",
    "\n",
    "Ta dùng model logistic regression để thực hiện train trên tập dữ liệu gồm có tập train và tập validation để tối ưu hóa kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trainVal là tập dữ liệu gồm tạp train và validation\n",
    "X_counts = count_vect.transform(X_trainVal)\n",
    "X_tfidf = tfidf_transformer.transform(X_counts)\n",
    "\n",
    "lr = LogisticRegression(n_jobs=1, C=1e5, max_iter=100, solver='lbfgs', multi_class='auto')\n",
    "last_lr_clf = lr.fit(X_tfidf, y_trainVal)\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "\n",
    "last_lr_predict = last_lr_clf.predict(X_test_tfidf)\n",
    "last_lr_test_score = accuracy_score(y_test, last_lr_predict) * 100\n",
    "print(\"Logistic regression test Accuracy Score -> \", last_lr_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi dự đoán với tập test ta thu được score: 85.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dự đoán với dữ liệu bất kì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = [\"Bàn phím acer\", \"lược sử loài người\", \"Trái đất hình thành như thế nào?\",\n",
    "             \"Như là giấc mơ\", \"Găng tay xe đạp\", \"Bình nước nóng sanyo\"]\n",
    "X_input_counts = count_vect.transform(X_input)\n",
    "X_input_tfidf = tfidf_transformer.transform(X_input_counts)\n",
    "x_input_predict= last_lr_clf.predict(X_input_tfidf)\n",
    "counter = 0\n",
    "for doc, category_id in zip(X_input, x_input_predict):\n",
    "    print('%r => %s' % (doc, textProcessor.id_to_categoryname(category_id)))\n",
    "    if(counter == 10):\n",
    "        break\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
